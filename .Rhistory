df=data.frame(region=state.region, #create new data frame using r objects
state=state.name,
abbrev.=state.abb)
covid_w_region <- merge(covid, df, by = "state", all.x = TRUE)
#compute the daily counts and cumulative totals for both cases and deaths.
#We will do this for each region.
library(dplyr)
covid_w_region <- covid_w_region %>%
arrange(state, date)
covid_w_region <- covid_w_region %>%
group_by(region, state) %>%
mutate(                                         #add new columns w/ calculations
daily_cases = cases - lag(cases, default = 0), #This gives the value of cases from the previous row (the previous day). If it's the first row (the first date), the default = 0 argument means that it will return 0 because there is no previous row.
daily_deaths = deaths - lag(deaths, default = 0),
cumulative_cases = cumsum(daily_cases),
cumulative_deaths = cumsum(daily_deaths)
) %>%
ungroup()
#To make the data suitable for plotting with ggplot2, we need to reshape it from a wide format (with separate columns for cases, deaths, etc.) to a long format.
library(tidyr)
covid_long <- covid_w_region %>%
pivot_longer(cols = c(daily_cases, daily_deaths, cumulative_cases, cumulative_deaths),
names_to = "metric", values_to = "value")
#The facet_wrap() function allows us to create a separate plot for each region.
library(ggplot2)
ggplot(covid_long, aes(x = as.Date(date), y = value, color = metric)) +
geom_line() +
facet_wrap(~ region, scales = "free_y") +
labs(
title = "Cumulative COVID-19 Cases & Deaths by Region",
x = "Date",
y = "Count",
color = "Metric"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),
panel.grid.major = element_line(color = "black")
)
View(covid_long)
View(covid_w_region)
filter<- covid_long %>%
filter(metric= "cumulative_cases" & "cumulative_deaths")
filter<- covid_long %>%
filter(metric== "cumulative_cases" & "cumulative_deaths")
filter<- covid_long %>%
filter(metric== "cumulative_cases", metric== "cumulative_deaths")
View(filter)
filter<- covid_long %>%
filter(metric== "cumulative_cases" & "cumulative_deaths")
covid_long <- covid_w_region %>%
pivot_longer(cols = c(cumulative_cases, cumulative_deaths),
names_to = "metric", values_to = "value")
ggplot(covid_long, aes(x = date, y = value, color = metric)) +
geom_line() +
facet_wrap(~ region, scales = "free_y") +
labs(
title = "Cumulative COVID-19 Cases & Deaths by Region",
x = "Date",
y = "Count",
color = "Metric"
) +
theme_minimal()
covid_deaths_data <- covid_w_region %>%
select(date, state, region, deaths, cumulative_deaths)
covid_deaths_data <- covid_w_region %>%
select(date, state, region, deaths, cumulative_cases)
View(covid_deaths_data)
covid_deaths_long <- covid_deaths_data %>%
pivot_longer(cols = c(deaths, cumulative_cases),
names_to = "metric",
values_to = "count")
View(covid_deaths_long)
ggplot(covid_deaths_long, aes(x = date, y = count, color = metric)) +
geom_line() +  # Line plot
facet_wrap(~ region, scales = "free_y") +  # Facet by region
labs(title = "COVID-19 Deaths and Cumulative Deaths by Region",
x = "Date",
y = "Count",
color = "Metric") +
theme_minimal() +  # Clean theme
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave("covid_cases_deaths_by_region.png", width = 12, height = 8, dpi = 300)
ggsave(imgs/"covid_cases_deaths_by_region.png", width = 12, height = 8, dpi = 300)
ggsave("imgs/covid_cases_deaths_by_region.png", width = 12, height = 8, dpi = 300)
covid_w_region <- inner_join(df, covid, by= "state") #innerjoin (df1, df2, join by=)
View(covid_w_region)
covid_w_region <- inner_join(df, covid, by= "state")%>% #innerjoin (df1, df2, join by=)
group_by(region,date)
covid_w_region <- inner_join(df, covid, by= "state")%>% #innerjoin (df1, df2, join by=)
group_by(region,date)%>% #group by region for each date
summarize(cases = sum(cases),
deaths = sum(deaths))
covid_w_region <- inner_join(df, covid, by= "state")%>% #innerjoin (df1, df2, join by=)
group_by(region,date)%>% #group by region for each date
summarize(cases = sum(cases),
deaths = sum(deaths)) %>% #compute the daily counts and cumulative totals for both cases and deaths.
pivot_longer(cols= c(cases, deaths),
names_to= "type",
values_to = "count")
covid_w_region %>% #make facet grid when seeing realtionship b/w 2 variables.by region and date
ggplot(aes(x= date, y=count)) +
geom_line() +
facet_grid(type ~ region, scales="free_y") +
theme_bw()
covid_w_region %>% #make facet grid when seeing realtionship b/w 2 variables.by region and date
ggplot(aes(x= date, y= count)) +
geom_line()
covid_w_region %>% #make facet grid when seeing realtionship b/w 2 variables.by region and date
ggplot(aes(x= date, y= count)) +
geom_line() +
facet_grid(type~region, scales="free_y") +
theme_bw()
ggsave("covid_cases_deaths_by_region.png", width = 12, height = 8, dpi = 300)
airquality=airquality
?airquality
library(tidyverse)
install.packages("visdat")
library(visdat)
vis_dat(airquality)
vis_miss(airquality)
airquality1=airquality  #load air quality data from r.
airquality1<- airquality1 %>%
drop_na()
airquality1<- airquality1 %>%
drop_na()
View(airquality1)
airquality1=airquality
library(tidyverse)
install.packages("visdat")
library(visdat)
vis_dat(airquality1)
vis_miss(airquality1)
airquality1<- airquality1 %>% #remove na values
drop_na()
vis_miss(airquality1)
#formula for linear model lm(y ~ x, data= data set)
airquality_lm(Ozone ~ Solar.R, data= airquality1)
#formula for linear model lm(y ~ x, data= data set)
airquality_lm<- lm(Ozone ~ Solar.R, data= airquality1)
View(airquality_lm)
summary(airquality_lm)
plot(airquality_lm)
summary(airquality_lm) #shows statistic summary
summary(airquality_lm) #shows statistic summary
#formula for linear model lm(y ~ x, data= data set)
airquality_lm<- lm(Ozone ~ Temp, data= airquality1)
summary(airquality_lm) #shows statistic summary
plot(airquality_lm)
airquality1 %>% distinct()
summary(airquality_lm) #shows statistic summary
#formula for linear model lm(y ~ x, data= data set) Choosing temp, bc can see in the table as it goes up
airquality_lm<- lm(Ozone ~ Solar.R, data= airquality1)
summary(airquality_lm) #shows statistic summary
vis_cor(airquality_lm)
vis_cor(airquality1)
airquality1=airquality
library(tidyverse)
install.packages("visdat")
library(visdat)
vis_dat(airquality1)
vis_miss(airquality1)
airquality1<- airquality1 %>% #remove na values
drop_na()
vis_miss(airquality1)
airquality_lm<- lm(Ozone ~ Solar.R, data= airquality1)
summary(airquality_lm)
#Use broom::augment to predict the Ozone of the cleaned data
library(broom)
augmented_covid <- augment(airquality_lm, data = airquality1)
View(augmented_covid)
ggplot(augmented_covid, aes(x = .fitted, y = Ozone)) +
geom_point(color = "blue") +             # Actual vs predicted points
geom_abline(intercept = 0, slope = 1,   # Line y = x for comparison
color = "red", linetype = "dashed") +  # Reference line
labs(title = "Actual vs Predicted Ozone",
x = "Predicted Ozone",
y = "Actual Ozone") +
theme_minimal()
#Add a red line to show where the actual and predicted values are equal This can be done by plotting a 1:1 line (e.g. intercept 0, slope 1) with geom_abline(intercept = 0, slope = 1, color = "red")
#Add a subtitle to the plot showing the correlation between the actual and predicted values are equal This can be done by plotting a 1:1 line (e.g. intercept 0, slope 1) with
#paste("Correlation:", round(cor(a$Ozone, a$.fitted),2)) assuming your augmented data object is called a
correlation_value <- round(cor(augmented_covid$Ozone, augmented_covid$.fitted), 2)
ggplot(augmented_covid, aes(x = .fitted, y = Ozone)) +
geom_point(color = "blue") +             # Actual vs predicted points
geom_abline(intercept = 0, slope = 1,   # Line y = x for comparison
color = "red", linetype = "dashed") +  # Reference line
labs(title = "Actual vs Predicted Ozone",
subtitle = paste("Correlation:", correlation_value),
x = "Predicted Ozone",
y = "Actual Ozone") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
install.packages("visdat")
library(visdat)
is there a relationship between car weight and miles per gallon in the mtcars dataset?”.
explortory data analysis
Exploratory data Analysis (2016) Peng
knitr::opts_chunk$set(echo = TRUE)
penguins<-palmerpenguins::penguins_raw
View(penguins)
str(penguins)
typeof(penguins)
class(penguins)
mode(penguins)
sapply(penguins, is.numeric)
Be alert to structure and possible data problems or anomalies.
str(penguins)
library(visdat)
summary(penguins)
table(penguin)
table(penguins)
vis_dat(penguins)
range(penguins$`Sample Number`)
range(penguins$`Sample Number`,penguins$`Culmen Length (mm)`)
range(penguins$`Sample Number`)
range(penguins$`Culmen Length (mm)`)
range(penguins$`Culmen Length (mm)`)
range(penguins$`Culmen Depth (mm)`)
penguins %>% drop_na %>%range(penguins$`Culmen Length (mm)`)
penguins %>% na_drop %>%range(penguins$`Culmen Length (mm)`)
penguins %>% na.rm= TRUE %>%range(penguins$`Culmen Length (mm)`)
penguins %>% rm.na= TRUE %>%range(penguins$`Culmen Length (mm)`)
penguins %>% drop_na() %>% range(penguins$`Culmen Length (mm)`)
library(tidyr)
library(tidyverse)
penguins %>% drop_na() %>% range(penguins$`Culmen Length (mm)`)
penguins %>%
drop_na() %>%
range(`Culmen Length (mm)`)
penguins %>%
drop_na() %>%
range(,`Culmen Length (mm)`)
penguins <-penguins %>%
drop_na()
range(penguins$`Culmen Length (mm)`)
range(penguins$`Culmen Depth (mm)`)
range(penguins$`Flipper Length (mm)`)
range(penguins$`Body Mass (g)`)
range(penguins$`Delta 15 N (o/oo)`)
range(penguins$`Delta 13 C (o/oo)`)
#mean
skimr::skim(penguins$`Sample Number`)
skimr::skim(penguins$`Culmen Length (mm)`)
skimr::skim(penguins$`Culmen Depth (mm)`)
skimr::skim(penguins$`Flipper Length (mm)`)
skimr::skim(penguins$`Body Mass (g)`)
skimr::skim(penguins$`Delta 15 N (o/oo)`)
skimr::skim(penguins$`Delta 13 C (o/oo)`)
#mean
summary(penguins$`Sample Number`)
summary(penguins$`Culmen Length (mm)`)
summary(penguins$`Culmen Depth (mm)`)
summary(penguins$`Flipper Length (mm)`)
summary(penguins$`Body Mass (g)`)
summary(penguins$`Delta 15 N (o/oo)`)
summary(penguins$`Delta 13 C (o/oo)`)
class(penguins)
penguins %>%
count(species)
penguins %>%
count(Species)
penguins %>%
count(Island)
penguins %>%
count(Sex)
penguins %>%
count(Species)
penguins %>%
count(Island)
penguins %>%
count(Island)
penguins %>%
count(Sex)
table(penguins$flipper_length_mm)
table(penguins$'Flipper Length')
table(penguins$`Flipper Length (mm)`)
# Table the binary variable: sex
table(penguins$Sex)
# View the first few rows (top of the dataset)
head(penguins)
# View the last few rows (bottom of the dataset)
tail(penguins)
skimr::skim(penguins)
# Summary statistics of body mass by island
penguins_summary <- penguins %>%
group_by(island) %>%
summarise(
mean_weight = mean(body_mass_g, na.rm = TRUE),
median_weight = median(body_mass_g, na.rm = TRUE),
sd_weight = sd(body_mass_g, na.rm = TRUE),
min_weight = min(body_mass_g, na.rm = TRUE),
max_weight = max(body_mass_g, na.rm = TRUE)
)
# Summary statistics of body mass by island
penguins_summary <- penguins %>%
group_by(Island) %>%
summarise(
mean_weight = mean(`Body Mass (g)`, na.rm = TRUE),
median_weight = median(`Body Mass (g)`, na.rm = TRUE),
sd_weight = sd(`Body Mass (g)`, na.rm = TRUE),
min_weight = min(`Body Mass (g)`, na.rm = TRUE),
max_weight = max(`Body Mass (g)`, na.rm = TRUE)
)
# View summary statistics
print(penguins_summary)
ggscatter(penguins, x = Island, y = `Body Mass (g)`,
color = "Island", add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
library(ggpubr)
ggscatter(penguins, x = Island, y = `Body Mass (g)`,
color = "Island", add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
ggscatter(penguins, x = Island, y = `Body Mass (g)`,
color = Island, add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
ggscatter(penguins, x = Island, y = `Body Mass (g)`,
color = Island, add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
ggscatter(penguins, x = Species, y = `Body Mass (g)`,
color = Island, add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
ggscatter(penguins, x = Species, y = `Body Mass (g)`,
color="Island", add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
ggscatter(penguins, x = "Species", y = "`Body Mass (g)`",
color="Island", add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
ggscatter(penguins, x = "Island", y = "Body Mass (g)",
color="Island", add = "reg.line", conf.int = TRUE) +
labs(title = "Island vs. Penguin Body Mss (g)",
x = "Island", y = "Body size(g)")
ggscatter(penguins, x = "", y = "Body Mass (g)",
color = "Island", add = "reg.line", ellipse = TRUE, conf.int = TRUE) +
labs(title = "Island vs. Body Mass (g)",
x = "", y = "Body Mass (g)") +
facet_wrap(~Island)
ggscatter(penguins, x = "", y = "`Body Mass (g)`",
color = "Island", add = "reg.line", ellipse = TRUE, conf.int = TRUE) +
labs(title = "Island vs. Body Mass (g)",
x = "", y = "Body Mass (g)") +
facet_wrap(~Island)
ggscatter(penguins, x = "", y = `Body Mass (g)`,
color = "Island", add = "reg.line", ellipse = TRUE, conf.int = TRUE) +
labs(title = "Island vs. Body Mass (g)",
x = "", y = "Body Mass (g)") +
facet_wrap(~Island)
ggplot(penguins, aes(x = `Body Mass (g)`, fill = Island)) +
geom_histogram(binwidth = 100, position = "dodge", alpha = 0.7) +
labs(title = "Body Mass Distribution by Island",
x = "Body Mass (grams)", y = "Frequency") +
facet_wrap(~island) +
theme_minimal()
ggplot(penguins, aes(x = `Body Mass (g)`, fill = Island)) +
geom_histogram(binwidth = 100, position = "dodge", alpha = 0.7) +
labs(title = "Body Mass Distribution by Island",
x = "Body Mass (grams)", y = "Frequency") +
facet_wrap(~Island) +
theme_minimal()
summary(penguins)
table(penguins)
summary(penguins)
vis_dat(penguins)
penguins <-penguins %>%
drop_na()
#range
range(penguins$`Sample Number`)
range(penguins$`Culmen Length (mm)`)
range(penguins$`Culmen Depth (mm)`)
range(penguins$`Flipper Length (mm)`)
range(penguins$`Body Mass (g)`)
range(penguins$`Delta 15 N (o/oo)`)
range(penguins$`Delta 13 C (o/oo)`)
airquality<-airquality
str(airquality)
summary(airquality)
# Perform Shapiro-Wilk normality test
shapiro.test(airquality$Ozone)
# Perform Shapiro-Wilk normality test
shapiro.test(airquality$Ozone)
shapiro.test(airquality$Temp)
shapiro.test(airquality$Solar.R)
shapiro.test(airquality$Wind)
#remove na values
airquality_seasons <- airquality %>%
drop_na()
View(airquality)
# Create a new column 'Season' based on the 'Month' column
airquality_seasons <- airquality_seasons %>%
mutate(season = case_when(
Month == 11 | Month == 12 | Month == 1 ~ "Winter",
Month == 2 | Month == 3 | Month == 4 ~ "Spring",
Month == 5 | Month == 6 | Month == 7 ~ "Summer",
Month == 8 | Month == 9 | Month == 10 ~ "Fall",
TRUE ~ "Unknown"  # Handling any missing values (NA) if necessary
))
View(airquality_seasons)
# Count the number of observations for each season
table(airquality_seasons$season)
airquality_seasons <- airquality
airquality_seasons <- airquality_seasons %>%
mutate(season = case_when(
Month == 11 | Month == 12 | Month == 1 ~ "Winter",
Month == 2 | Month == 3 | Month == 4 ~ "Spring",
Month == 5 | Month == 6 | Month == 7 ~ "Summer",
Month == 8 | Month == 9 | Month == 10 ~ "Fall",
TRUE ~ "Unknown"  # Handling any missing values (NA) if necessary
))
# Count the number of observations for each season
table(airquality_seasons$season)
library(recipes)
#  recipe to normalize the variables Temp, Solar.R, and Wind
recipe_obj <- recipe(~ Temp + Solar.R + Wind + season, data = airquality_seasons) %>%
# Impute missing values with the mean for numeric columns
step_meanimpute(all_numeric(), -all_outcomes()) %>%
# Normalize the numeric predictors
step_normalize(all_numeric(), -all_outcomes())
#  recipe to normalize the variables Temp, Solar.R, and Wind
recipe_normalize <- recipe(~ Temp + Solar.R + Wind + season, data = airquality_seasons) %>%
# Impute missing values with the mean for numeric columns
step_impute_mean(all_numeric(), -all_outcomes()) %>%
# Normalize the numeric predictors
step_normalize(all_numeric(), -all_outcomes())
# Preview the recipe
recipe_normalize
# Prepare the recipe (estimate means and scaling parameters)
recipe_prep <- prep(recipe_normalize, training = airquality_seasons)
View(recipe_prep)
# Prepare the recipe (estimate means and scaling parameters)
recipe_prep <- prep(recipe_normalize, training = airquality_seasons)
# Apply the transformations to the data (bake)
airquality_processed <- bake(recipe_prep, new_data = airquality_seasons)
# View the processed dataset
head(airquality_processed)
lm(Ozone ~ ., data = airquality_seasons) %>%
summary()
# View the su
library(broom)
# broom::augment() function can be used to add the fitted values and residuals to your data
# Augment the data with fitted values and residuals
augmented_data <- augment(lm_model, data = airquality_seasons)
# Fit the linear regression model. lm() function to fit the model, and the . notation to include all predictor variables automatically.
airquality_lm<-lm(Ozone ~ ., data = airquality_seasons) %>%
summary()
# Fit the linear regression model. lm() function to fit the model, and the . notation to include all predictor variables automatically.
airquality_lm<-lm(Ozone ~ ., data = airquality_seasons) %>%
summary()
# broom::augment() function can be used to add the fitted values and residuals to your data
# Augment the data with fitted values and residuals
augmented_data <- augment(lm_model, data = airquality_seasons)
# broom::augment() function can be used to add the fitted values and residuals to your data
# Augment the data with fitted values and residuals
augmented_data <- augment(airquality_lm, data = airquality_seasons)
# Fit the linear regression model. lm() function to fit the model, and the . notation to include all predictor variables automatically.
airquality_lm<-lm(Ozone ~ ., data = airquality_seasons) %>%
summary()
View(airquality_lm)
# Fit the linear regression model. lm() function to fit the model, and the . notation to include all predictor variables automatically.
airquality_lm <- lm(Ozone ~ ., data = airquality_seasons) %>%
summary()
summary(airquality_lm)
# Augment the data with fitted values and residuals
augmented_data <- augment(airquality_lm, data = airquality_seasons)
install.packages("broom")
# Fit the linear regression model. lm() function to fit the model, and the . notation to include all predictor variables automatically.
airquality_lm <- lm(Ozone ~ ., data = airquality_seasons)
summary(airquality_lm)
# broom::augment() function can be used to add the fitted values and residuals to your data
# Augment the data with fitted values and residuals
augmented_data <- augment(airquality_lm, data = airquality_seasons)
sum(is.na(airquality_with_seasons))
sum(is.na(airquality_seasons))
# broom::augment() function can be used to add the fitted values and residuals to your data
airquality_nona <- na.omit(airquality_seasons)
# Augment the data with fitted values and residuals
augmented_data <- augment(airquality_lm, data = airquality_seasons)
# broom::augment() function can be used to add the fitted values and residuals to your data
#remove the na values
airquality_nona <- na.omit(airquality_seasons)
# Augment the data with fitted values and residuals
augmented_data <- augment(airquality_lm, data = airquality_nona)
# View the first few rows of the augmented data
head(augmented_data)
# Histogram of residuals
hist_plot <- ggplot(augmented_data, aes(x = .resid)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
labs(title = "Histogram of Residuals", x = "Residuals", y = "Frequency") +
theme_minimal()
# Q-Q plot of residuals
qq_plot <- ggplot(augmented_data, aes(sample = .resid)) +
geom_qq() +
geom_qq_line() +
labs(title = "Q-Q Plot of Residuals") +
theme_minimal()
library(gridExtra)
# Use ggarrange to combine the two plots into one image
grid.arrange(hist_plot, qq_plot, ncol = 2)
# Scatter plot of Actual vs. Predicted Ozone
ggscatter(augmented_data, x = "Ozone", y = ".fitted",
add = "reg.line", conf.int = TRUE,
cor.coef = TRUE, cor.method = "spearman",
ellipse = TRUE) +
labs(title = "Actual vs. Predicted Ozone") +
theme_minimal()
